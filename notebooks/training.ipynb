{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-15T16:00:33.752056Z",
     "end_time": "2023-05-15T16:00:33.754854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/kanstantsin/workspace/yolov8-sd/venv/bin/python'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.101 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.96 üöÄ Python-3.9.6 torch-2.0.1 CPU\n",
      "\u001B[34m\u001B[1myolo/engine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.2, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.1, hsv_s=0.7, hsv_v=0.4, degrees=15, translate=0.1, scale=0.5, shear=0.05, perspective=0.00035, flipud=0.5, fliplr=0.5, mosaic=0.5, mixup=0.15, copy_paste=0.1, cfg=None, v5loader=True, tracker=botsort.yaml, save_dir=/Users/kanstantsin/workspace/yolov8-sd/runs/detect/train39\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model/train\n",
      "\n",
      "\n",
      "here trainer. py\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mkanstantsin\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/kanstantsin/workspace/yolov8-sd/notebooks/wandb/run-20230515_161244-hc1eekkm</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/kanstantsin/YOLOv8/runs/hc1eekkm' target=\"_blank\">dainty-resonance-2</a></strong> to <a href='https://wandb.ai/kanstantsin/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/kanstantsin/YOLOv8' target=\"_blank\">https://wandb.ai/kanstantsin/YOLOv8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/kanstantsin/YOLOv8/runs/hc1eekkm' target=\"_blank\">https://wandb.ai/kanstantsin/YOLOv8/runs/hc1eekkm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "WARNING ‚ö†Ô∏è 'v5loader' feature is deprecated and will be removed soon. You can train using the default YOLOv8 dataloader instead, no argument is needed.\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/kanstantsin/workspace/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "WARNING ‚ö†Ô∏è 'v5loader' feature is deprecated and will be removed soon. You can train using the default YOLOv8 dataloader instead, no argument is needed.\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/kanstantsin/workspace/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1m/Users/kanstantsin/workspace/yolov8-sd/runs/detect/train39\u001B[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G     0.0144      1.713      1.935        197        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:55<00:00,  6.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:21<00:00,  5.28s/it]\n",
      "                   all        128        929      0.631      0.564      0.599      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3         0G    0.01332      1.609      1.839        185        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:54<00:00,  6.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:21<00:00,  5.35s/it]\n",
      "                   all        128        929      0.643      0.557      0.591      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3         0G    0.01199      1.402       1.65        186        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:58<00:00,  7.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:21<00:00,  5.44s/it]\n",
      "                   all        128        929      0.652      0.546       0.58      0.395\n",
      "\n",
      "3 epochs completed in 0.066 hours.\n",
      "Optimizer stripped from /Users/kanstantsin/workspace/yolov8-sd/runs/detect/train39/weights/last.pt, 6.5MB\n",
      "Optimizer stripped from /Users/kanstantsin/workspace/yolov8-sd/runs/detect/train39/weights/best.pt, 6.5MB\n",
      "\n",
      "Validating /Users/kanstantsin/workspace/yolov8-sd/runs/detect/train39/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.96 üöÄ Python-3.9.6 torch-2.0.1 CPU\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:19<00:00,  4.96s/it]\n",
      "                   all        128        929      0.632      0.563      0.599      0.433\n",
      "                person        128        254      0.779      0.669      0.729      0.509\n",
      "               bicycle        128          6      0.554      0.333      0.318      0.274\n",
      "                   car        128         46      0.542      0.217      0.278       0.17\n",
      "            motorcycle        128          5      0.589      0.865       0.92      0.684\n",
      "              airplane        128          6      0.785          1      0.948      0.728\n",
      "                   bus        128          7      0.577      0.714      0.713       0.66\n",
      "                 train        128          3      0.552      0.667      0.695      0.592\n",
      "                 truck        128         12      0.724      0.417      0.457      0.286\n",
      "                  boat        128          6          0          0     0.0429     0.0074\n",
      "         traffic light        128         14       0.55      0.214      0.209      0.141\n",
      "             stop sign        128          2      0.668          1      0.995      0.648\n",
      "                 bench        128          9          1      0.664      0.715      0.442\n",
      "                  bird        128         16      0.818       0.75      0.776      0.424\n",
      "                   cat        128          4      0.864          1      0.995      0.822\n",
      "                   dog        128          9      0.601      0.778      0.743      0.581\n",
      "                 horse        128          2      0.526          1      0.995      0.547\n",
      "              elephant        128         17      0.957      0.706      0.796       0.61\n",
      "                  bear        128          1      0.594          1      0.995      0.995\n",
      "                 zebra        128          4      0.841          1      0.995      0.972\n",
      "               giraffe        128          9        0.9      0.778       0.81      0.554\n",
      "              backpack        128          6      0.548      0.333      0.385      0.215\n",
      "              umbrella        128         18       0.79      0.444      0.502      0.304\n",
      "               handbag        128         19       0.57      0.105      0.216       0.11\n",
      "                   tie        128          7      0.982      0.714      0.722      0.502\n",
      "              suitcase        128          4      0.747          1      0.995      0.573\n",
      "               frisbee        128          5       0.55        0.8       0.76      0.665\n",
      "                  skis        128          1      0.494          1      0.995      0.497\n",
      "             snowboard        128          7      0.652      0.429      0.441      0.393\n",
      "           sports ball        128          6      0.568      0.333      0.476      0.275\n",
      "                  kite        128         10      0.563        0.5      0.472      0.134\n",
      "          baseball bat        128          4      0.401        0.5        0.5      0.175\n",
      "        baseball glove        128          7      0.561      0.429      0.433      0.276\n",
      "            skateboard        128          5      0.838        0.6      0.603      0.436\n",
      "         tennis racket        128          7      0.669      0.286      0.528      0.353\n",
      "                bottle        128         18      0.431        0.5      0.411      0.256\n",
      "            wine glass        128         16      0.693      0.375      0.492      0.303\n",
      "                   cup        128         36      0.664      0.333      0.408      0.297\n",
      "                  fork        128          6      0.522      0.167       0.28      0.192\n",
      "                 knife        128         16      0.862      0.562      0.666      0.387\n",
      "                 spoon        128         22      0.637      0.182      0.338      0.149\n",
      "                  bowl        128         28      0.599      0.643      0.561      0.464\n",
      "                banana        128          1      0.123          1      0.142     0.0284\n",
      "              sandwich        128          2      0.392        0.5      0.448      0.428\n",
      "                orange        128          4          1      0.346      0.888      0.525\n",
      "              broccoli        128         11      0.343      0.182      0.262      0.217\n",
      "                carrot        128         24      0.676      0.542      0.703      0.434\n",
      "               hot dog        128          2      0.336        0.5      0.502      0.502\n",
      "                 pizza        128          5      0.728          1      0.995      0.761\n",
      "                 donut        128         14      0.712      0.929      0.871      0.774\n",
      "                  cake        128          4      0.667          1      0.995       0.88\n",
      "                 chair        128         35      0.506      0.571      0.464      0.235\n",
      "                 couch        128          6      0.396        0.5      0.532      0.426\n",
      "          potted plant        128         14      0.536       0.66      0.722      0.465\n",
      "                   bed        128          3        0.9      0.667      0.775      0.602\n",
      "          dining table        128         13      0.333      0.538      0.439      0.383\n",
      "                toilet        128          2          1      0.916      0.995      0.946\n",
      "                    tv        128          2      0.278      0.592      0.695      0.606\n",
      "                laptop        128          3          1          0      0.211      0.182\n",
      "                 mouse        128          2          1          0          0          0\n",
      "                remote        128          8       0.84        0.5      0.623      0.511\n",
      "            cell phone        128          8          0          0     0.0331     0.0291\n",
      "             microwave        128          3      0.463          1       0.83      0.699\n",
      "                  oven        128          5      0.335        0.4      0.348      0.276\n",
      "                  sink        128          6      0.398      0.231      0.208      0.144\n",
      "          refrigerator        128          5      0.415       0.43      0.623      0.497\n",
      "                  book        128         29      0.505      0.103      0.435      0.169\n",
      "                 clock        128          9          1      0.885      0.932      0.744\n",
      "                  vase        128          2      0.272          1      0.828      0.745\n",
      "              scissors        128          1          1          0      0.166     0.0498\n",
      "            teddy bear        128         21      0.959      0.429      0.603      0.377\n",
      "            toothbrush        128          5          1      0.554      0.928      0.511\n",
      "Speed: 1.5ms preprocess, 145.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001B[1m/Users/kanstantsin/workspace/yolov8-sd/runs/detect/train39\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/vb/jnprv7bd7y33z4_ppf6vt1xr0000gn/T/ipykernel_4889/3584776049.py\", line 37, in <module>\n",
      "    model.train(data=\"coco128.yaml\", epochs=3, augment=True, v5loader=True, **args)  # train the model\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/ultralytics/yolo/engine/model.py\", line 371, in train\n",
      "    # Update model and cfg after training\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/ultralytics/yolo/engine/trainer.py\", line 194, in train\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/ultralytics/yolo/engine/trainer.py\", line 402, in _do_train\n",
      "    if self.args.plots:\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/ultralytics/yolo/engine/trainer.py\", line 558, in final_eval\n",
      "    self.run_callbacks('on_fit_epoch_end')\n",
      "AttributeError: 'tuple' object has no attribute 'pop'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/kanstantsin/workspace/yolov8-sd/venv/lib/python3.9/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model :  YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model =  YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "args = {'lr0': 0.01,\n",
    "        'lrf': 0.1,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0005,\n",
    "        'warmup_epochs': 3.0,\n",
    "        'warmup_momentum': 0.8,\n",
    "        'warmup_bias_lr': 0.1,\n",
    "        'box': 0.05,\n",
    "        'cls': 0.3,\n",
    "        # 'cls_pw': 1.0,\n",
    "        # 'obj': 0.7,\n",
    "        # 'obj_pw': 1.0,\n",
    "        'iou': 0.20,  # iou_t -> iou\n",
    "        # 'anchor_t': 10.0,\n",
    "        # 'fl_gamma': 0.0,\n",
    "        'hsv_h': 0.1,\n",
    "        'hsv_s': 0.7,\n",
    "        'hsv_v': 0.4,\n",
    "        'degrees': 15,\n",
    "        'translate': 0.1,\n",
    "        'scale': 0.5,\n",
    "        'shear': 0.05,\n",
    "        'perspective': 0.00035,\n",
    "        'flipud': 0.5,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 0.5,\n",
    "        'mixup': 0.15,\n",
    "        'copy_paste': 0.1}\n",
    "\n",
    "model.train(data=\"coco128.yaml\", epochs=3, augment=True, v5loader=True, **args)  # train the model\n",
    "metrics = model.val(augment=True)  # evaluate model performance on the validation set\n",
    "# results :  model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "# success :  model.export(format=\"onnx\")  # export the model to ONNX format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T15:57:11.116508Z",
     "end_time": "2023-05-10T16:01:35.669709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
